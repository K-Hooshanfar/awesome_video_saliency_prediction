# <p align=center>`Awesome Video Saliency Prediction`</p> # 

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

# Visual
* [2018] DeepVS: A Deep Learning Based Video Saliency Prediction Approach, [paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Lai_Jiang_DeepVS_A_Deep_ECCV_2018_paper.pdf), [github](https://github.com/remega/OMCNN_2CLSTM)
* [2019] DeepVS: A Deep Learning Based Video Saliency Prediction Approach, [paper](https://arxiv.org/pdf/1907.01869v4), [github](https://github.com/Linardos/SalEMA)
* [2019] TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection, [paper](https://arxiv.org/abs/1908.05786), [github](https://github.com/MichiganCOG/TASED-Net)
* [2020] DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0031320320300406?ref=pdf_download&fr=RR-2&rr=8c70c90d0dbbd25c)
* [2021] Video saliency prediction via spatio-temporal reasoning, [paper](https://www.sciencedirect.com/science/article/pii/S092523122101170X?ref=pdf_download&fr=RR-2&rr=8c70d7f5db70d25c)
* [2021] Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network, [paper](https://arxiv.org/pdf/2001.00292), [github](https://github.com/cj4L/ESAN-VSP)
* [2021] Hierarchical Domain-Adapted Feature Learning for Video Saliency Prediction, [paper](https://arxiv.org/abs/2010.01220), [github](https://github.com/perceivelab/hd2s)
* [2021] SalED: Saliency prediction with a pithy encoder-decoder architecture sensing local and global information, [paper](https://www.sciencedirect.com/science/article/pii/S0262885621000548?via%3Dihub), [github](https://github.com/WZq975/SalED)
* [2021] STA3D: Spatiotemporally attentive 3D network for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0167865521001409?via%3Dihub)
* [2021] A Gated Fusion Network for Dynamic Saliency Prediction, [paper](https://arxiv.org/pdf/2102.07682)
* [2022] ECANet: Explicit cyclic attention-based network for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0925231221015022?via%3Dihub)
* [2022] An efficient saliency prediction model for Unmanned Aerial Vehicle video, [paper](https://www.sciencedirect.com/science/article/pii/S0924271622002763?ref=pdf_download&fr=RR-2&rr=8c71154b98711cc1#fig2)
* [2023] Accurate video saliency prediction via hierarchical fusion and temporal recurrence, [paper](https://www.sciencedirect.com/science/article/pii/S026288562300118X)
* [2023] Visual saliency assistance mechanism based on visually impaired navigation systems, [paper](https://www.sciencedirect.com/science/article/pii/S0141938223001154?ref=pdf_download&fr=RR-2&rr=8c710e95197d1cc1)
* [2023] GFNet: gated fusion network for video saliency prediction, [paper](https://link.springer.com/article/10.1007/s10489-023-04861-5)
* [2023] Transformer-Based Multi-Scale Feature Integration Network for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/document/10130326), [github](https://github.com/wusonghe/TMFI-Net)
* [2023] Multi-Scale Spatiotemporal Feature Fusion Network for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/document/10269025)
* [2024] Transformer-based Video Saliency Prediction with High Temporal Dimension Decoding, [paper](https://arxiv.org/pdf/2401.07942)
* [2024] SalFoM: Dynamic Saliency Prediction with Video Foundation Models, [paper](https://arxiv.org/pdf/2404.03097)
* [2024] Transformer-based multi-level attention integration network for video saliency prediction, [paper](https://link.springer.com/article/10.1007/s11042-024-19404-4)
* [2024] OFF-ViNet: Optical Flow-Based Feature Warping ViNet for Video Saliency Prediction Considering Future Prediction, [paper](https://ieeexplore.ieee.org/document/10508805?denied=)

# Audio–visual

* [2019] DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction, [paper](https://arxiv.org/abs/1905.10693), [github](https://github.com/hrtavakoli/DAVE)
* [2020] Audiovisual saliency prediction via deep learning, [paper](https://www.sciencedirect.com/science/article/pii/S0925231220318920?ref=pdf_download&fr=RR-2&rr=8c70cc4f993ad25c)
* [2020] STAViS: Spatio-Temporal AudioVisual Saliency Network, [paper](https://arxiv.org/abs/2001.03063), [github](https://github.com/atsiami/STAViS)
* [2020] Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model, [paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650409.pdf), [github](https://github.com/MinglangQiao/visual_audio_saliency)
* [2020] A Multimodal Saliency Model for Videos With High Audio-Visual Correspondence, [paper](https://ieeexplore.ieee.org/document/8962278)
* [2021] Joint learning of visual-audio saliency prediction and sound source localization on multi-face videos, [paper](https://arxiv.org/pdf/2111.08567)
* [2021] ViNet: Pushing the limits of Visual Modality for Audio-Visual Saliency Prediction, [paper](https://arxiv.org/pdf/2012.06170v3), [github](https://github.com/samyak0210/ViNet)
* [2021] A Novel Lightweight Audio-visual Saliency Model for Videos, [paper](https://ieeexplore.ieee.org/document/9428415)
* [2022] Dual Domain-Adversarial Learning for Audio-Visual Saliency Prediction, [paper](https://arxiv.org/pdf/2208.05220v2)
* [2022] Audio–visual collaborative representation learning for Dynamic Saliency Prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0950705122008486?via%3Dihub)
* [2023] CASP-Net: Rethinking Video Saliency Prediction from an Audio-VisualConsistency Perceptual Perspective, [paper](https://arxiv.org/abs/2303.06357)
* [2024] Audio-Visual Saliency Prediction with Multisensory Perception and Integration, [paper](https://www.sciencedirect.com/science/article/abs/pii/S0262885624000581), [github](https://github.com/oraclefina/MSPI)
* [2024] From Discrete Representation to Continuous Modeling: A Novel Audio-Visual Saliency Prediction Model With Implicit Neural Representations, [paper](https://ieeexplore.ieee.org/document/10502245)
* [2024] DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction, [paper](https://arxiv.org/abs/2403.01226), [github](https://github.com/junwenxiong/diff_sal)
  
# Datasets
* [2018] DeepVS: A Deep Learning Based Video Saliency Prediction Approach, [paper](https://arxiv.org/pdf/1709.06316v3), [github](https://github.com/remega/LEDOV-eye-tracking-database)
* [2020] MVVA Dataset: Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model, [paper](https://arxiv.org/abs/2103.15438), [github1](https://github.com/MinglangQiao/MVVA-Database), [github2](https://github.com/MinglangQiao/visual_audio_saliency)
* [2024] Saliency Prediction on Mobile Videos: A Fixation Mapping-Based Dataset and A Transformer Approach, [paper](https://ieeexplore.ieee.org/abstract/document/10360106), [github](https://github.com/wenshijie110/MVFormer)
* [2024] Audio-visual saliency prediction for movie viewing in immersive environments: Dataset and benchmarks, [paper](https://www.sciencedirect.com/science/article/pii/S1047320324000506)
* [2024] Video saliency prediction for First-Person View UAV videos: Dataset and benchmark, [paper](https://www.sciencedirect.com/science/article/pii/S0925231224006477?ref=pdf_download&fr=RR-2&rr=8c7102c00ad21cc1)
* [2024] Saliency Prediction of Sports Videos: A Large-Scale Database and a Self-Adaptive Approach, [paper](https://ieeexplore.ieee.org/abstract/document/10446481)





