# <p align=center>`Awesome Video Saliency Prediction`</p> # 

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

# Visual
* [2017] Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction, [paper](https://arxiv.org/abs/1607.04730), [github](https://github.com/cagdasbak/dynamicsaliency)
* [2018] Revisiting Video Saliency: A Large-scale Benchmark and a New Model, [paper](https://arxiv.org/abs/1801.07424), [github1](https://github.com/wenguanwang/DHF1K), [github2](https://github.com/Nablax/ACLnet-Pytorch)
* [2018] Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network, [paper](https://ieeexplore.ieee.org/document/8543830), [github](https://github.com/zhangkao/IIP_TwoS_Saliency)
* [2018] DeepVS: A Deep Learning Based Video Saliency Prediction Approach, [paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Lai_Jiang_DeepVS_A_Deep_ECCV_2018_paper.pdf), [github](https://github.com/remega/OMCNN_2CLSTM)
* [2018] Temporal Saliency Adaptation in Egocentric Videos, [paper](https://arxiv.org/pdf/1808.09559v2), [github](https://github.com/imatge-upc/saliency-2018-videosalgan)
* [2019] Temporal Recurrences for Video Saliency Prediction, [paper](https://doras.dcu.ie/23543/1/_BMVC__Simple_vs_complex_temporal_recurrences_for_video_saliency_prediction__Copy_.pdf), [github](https://github.com/juanjo3ns/SalBCE)
* [2019] Simple vs complex temporal recurrences for video saliency prediction, [paper](https://arxiv.org/pdf/1907.01869v4), [github](https://github.com/Linardos/SalEMA)
* [2019] TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection, [paper](https://arxiv.org/abs/1908.05786), [github](https://github.com/MichiganCOG/TASED-Net)
* [2019] Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks, [paper](https://ieeexplore.ieee.org/document/8811731?denied=), [github](https://github.com/ashleylqx/STRA-Net)
* [2020] Unified Image and Video Saliency Modeling, [paper](https://arxiv.org/abs/2003.05477), [github](https://github.com/rdroste/unisal)
* [2020] A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/document/9263359), [github](https://github.com/zhangkao/IIP_STRNN_Saliency)
* [2020] 3DSal: An Efficient 3D-CNN Architecture for Video Saliency Prediction, [paper](https://www.researchgate.net/publication/340024237_3DSAL_An_Efficient_3D-CNN_Architecture_for_Video_Saliency_Prediction), [github](https://github.com/YasserDA/Saliency-3DSal)
* [2020] DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0031320320300406?ref=pdf_download&fr=RR-2&rr=8c70c90d0dbbd25c)
* [2021] Video saliency prediction via spatio-temporal reasoning, [paper](https://www.sciencedirect.com/science/article/pii/S092523122101170X?ref=pdf_download&fr=RR-2&rr=8c70d7f5db70d25c)
* [2021] GASP: Gated Attention For Saliency Prediction, [paper](https://arxiv.org/pdf/2206.04590v1), [github](https://github.com/knowledgetechnologyuhh/gasp)
* [2021] Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network, [paper](https://arxiv.org/pdf/2001.00292), [github](https://github.com/cj4L/ESAN-VSP)
* [2021] Hierarchical Domain-Adapted Feature Learning for Video Saliency Prediction, [paper](https://arxiv.org/abs/2010.01220), [github](https://github.com/perceivelab/hd2s)
* [2021] Noise-Aware Video Saliency Prediction, [paper](https://arxiv.org/pdf/2104.08038v2), [github](https://github.com/NVlabs/NAT-saliency)
* [2021] SalED: Saliency prediction with a pithy encoder-decoder architecture sensing local and global information, [paper](https://www.sciencedirect.com/science/article/pii/S0262885621000548?via%3Dihub), [github](https://github.com/WZq975/SalED)
* [2021] STA3D: Spatiotemporally attentive 3D network for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0167865521001409?via%3Dihub)
* [2021] A Gated Fusion Network for Dynamic Saliency Prediction, [paper](https://arxiv.org/pdf/2102.07682)
* [2022] ECANet: Explicit cyclic attention-based network for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0925231221015022?via%3Dihub)
* [2022] An efficient saliency prediction model for Unmanned Aerial Vehicle video, [paper](https://www.sciencedirect.com/science/article/pii/S0924271622002763?ref=pdf_download&fr=RR-2&rr=8c71154b98711cc1#fig2), [github](https://github.com/zhangkao/IIP_UAVSal_Saliency)
* [2023] Accurate video saliency prediction via hierarchical fusion and temporal recurrence, [paper](https://www.sciencedirect.com/science/article/pii/S026288562300118X)
* [2023] Visual saliency assistance mechanism based on visually impaired navigation systems, [paper](https://www.sciencedirect.com/science/article/pii/S0141938223001154?ref=pdf_download&fr=RR-2&rr=8c710e95197d1cc1)
* [2023] GFNet: gated fusion network for video saliency prediction, [paper](https://link.springer.com/article/10.1007/s10489-023-04861-5)
* [2023] Transformer-Based Multi-Scale Feature Integration Network for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/document/10130326), [github](https://github.com/wusonghe/TMFI-Net)
* [2023] Spatio-Temporal Self-Attention Network for Video Saliency Prediction, [paper](https://arxiv.org/pdf/2108.10696v2), [github](https://github.com/come880412/STSANet)
* [2023] Multi-Scale Spatiotemporal Feature Fusion Network for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/document/10269025)
* [2023] TinyHD: Efficient Video Saliency Prediction with Heterogeneous Decoders using Hierarchical Maps Distillation, [paper](https://arxiv.org/pdf/2301.04619v1), [github](https://github.com/feiyanhu/tinyhd)
* [2023] UniST: Towards Unifying Saliency Transformer for Video Saliency Prediction and Detection, [paper](https://arxiv.org/pdf/2309.08220v1)
* [2024] Transformer-based Video Saliency Prediction with High Temporal Dimension Decoding, [paper](https://arxiv.org/pdf/2401.07942)
* [2024] SalFoM: Dynamic Saliency Prediction with Video Foundation Models, [paper](https://arxiv.org/pdf/2404.03097)
* [2024] Transformer-based multi-level attention integration network for video saliency prediction, [paper](https://link.springer.com/article/10.1007/s11042-024-19404-4)
* [2024] OFF-ViNet: Optical Flow-Based Feature Warping ViNet for Video Saliency Prediction Considering Future Prediction, [paper](https://ieeexplore.ieee.org/document/10508805?denied=)
* [2024] The Visual Saliency Transformer Goes Temporal: TempVST for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/document/10620181)
* [2025] TM2SP: A Transformer-based Multi-Level Spatiotemporal Feature Pyramid Network for Video Saliency Prediction, [paper](https://ieeexplore.ieee.org/abstract/document/10841372)
* [2025] Hierarchical spatiotemporal Feature Interaction Network for video saliency prediction, [paper](https://www.sciencedirect.com/science/article/abs/pii/S0262885625000010)
* [2025] Minimalistic Video Saliency Prediction via Efficient Decoder & Spatio Temporal Action Cues, [paper](https://arxiv.org/pdf/2502.00397v1)

# Audio–visual

* [2019] DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction, [paper](https://arxiv.org/abs/1905.10693), [github](https://github.com/hrtavakoli/DAVE)
* [2020] Audiovisual saliency prediction via deep learning, [paper](https://www.sciencedirect.com/science/article/pii/S0925231220318920?ref=pdf_download&fr=RR-2&rr=8c70cc4f993ad25c)
* [2020] STAViS: Spatio-Temporal AudioVisual Saliency Network, [paper](https://arxiv.org/abs/2001.03063), [github](https://github.com/atsiami/STAViS)
* [2020] Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model, [paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650409.pdf), [github](https://github.com/MinglangQiao/visual_audio_saliency)
* [2020] A Multimodal Saliency Model for Videos With High Audio-Visual Correspondence, [paper](https://ieeexplore.ieee.org/document/8962278)
* [2021] Joint learning of visual-audio saliency prediction and sound source localization on multi-face videos, [paper](https://arxiv.org/pdf/2111.08567)
* [2021] ViNet: Pushing the limits of Visual Modality for Audio-Visual Saliency Prediction, [paper](https://arxiv.org/pdf/2012.06170v3), [github](https://github.com/samyak0210/ViNet)
* [2021] Deep Audio-Visual Fusion Neural Network for Saliency Estimation, [paper](https://ieeexplore.ieee.org/document/9506089)
* [2021] Temporal-Spatial Feature Pyramid for Video Saliency Detection, [paper](https://arxiv.org/abs/2105.04213)
* [2021] A Novel Lightweight Audio-visual Saliency Model for Videos, [paper](https://ieeexplore.ieee.org/document/9428415)
* [2022] Dual Domain-Adversarial Learning for Audio-Visual Saliency Prediction, [paper](https://arxiv.org/pdf/2208.05220v2)
* [2022] Audio–visual collaborative representation learning for Dynamic Saliency Prediction, [paper](https://www.sciencedirect.com/science/article/pii/S0950705122008486?via%3Dihub)
* [2023] CASP-Net: Rethinking Video Saliency Prediction from an Audio-VisualConsistency Perceptual Perspective, [paper](https://arxiv.org/abs/2303.06357)
* [2024] Audio-Visual Saliency Prediction with Multisensory Perception and Integration, [paper](https://www.sciencedirect.com/science/article/abs/pii/S0262885624000581), [github](https://github.com/oraclefina/MSPI)
* [2024] From Discrete Representation to Continuous Modeling: A Novel Audio-Visual Saliency Prediction Model With Implicit Neural Representations, [paper](https://ieeexplore.ieee.org/document/10502245)
* [2024] DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction, [paper](https://arxiv.org/abs/2403.01226), [github](https://github.com/junwenxiong/diff_sal)
* [2024] Relevance-guided Audio Visual Fusion for Video Saliency Prediction, [paper](https://arxiv.org/pdf/2411.11454v1)
* [2025] Text-Audio-Visual-conditioned Diffusion Model for Video Saliency Prediction, [paper](https://arxiv.org/pdf/2504.14267)
* [2025] DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction, [paper](https://arxiv.org/pdf/2504.10070)

# Datasets
* [2018] DeepVS: A Deep Learning Based Video Saliency Prediction Approach, [paper](https://arxiv.org/pdf/1709.06316v3), [github](https://github.com/remega/LEDOV-eye-tracking-database)
* [2018] Revisiting Video Saliency: A Large-scale Benchmark and a New Model, [paper](https://arxiv.org/abs/1801.07424), [github](https://github.com/wenguanwang/DHF1K)
* [2020] MVVA Dataset: Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model, [paper](https://arxiv.org/abs/2103.15438), [github1](https://github.com/MinglangQiao/MVVA-Database), [github2](https://github.com/MinglangQiao/visual_audio_saliency)
* [2024] Saliency Prediction on Mobile Videos: A Fixation Mapping-Based Dataset and A Transformer Approach, [paper](https://ieeexplore.ieee.org/abstract/document/10360106), [github](https://github.com/wenshijie110/MVFormer)
* [2024] Audio-visual saliency prediction for movie viewing in immersive environments: Dataset and benchmarks, [paper](https://www.sciencedirect.com/science/article/pii/S1047320324000506)
* [2024] Video saliency prediction for First-Person View UAV videos: Dataset and benchmark, [paper](https://www.sciencedirect.com/science/article/pii/S0925231224006477?ref=pdf_download&fr=RR-2&rr=8c7102c00ad21cc1)
* [2024] Saliency Prediction of Sports Videos: A Large-Scale Database and a Self-Adaptive Approach, [paper](https://ieeexplore.ieee.org/abstract/document/10446481)





